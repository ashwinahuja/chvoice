{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio as ta\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "DEVICE = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class DSP:\n",
    "\n",
    "    def __init__(self, n_fft=254, hop_len=None):\n",
    "        \"\"\" signal processing utils using torchaudio\n",
    "        \"\"\"\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_len = n_fft//2 if hop_len is None else hop_len\n",
    "        self.stft = ta.transforms.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=self.hop_len,\n",
    "            win_length=n_fft,\n",
    "            power=None\n",
    "        )\n",
    "        self.amplitude_to_db = ta.transforms.AmplitudeToDB()\n",
    "        self.db_to_amplitude = lambda x: T.pow(T.pow(10.0, 0.1 * x), 1.)\n",
    "\n",
    "    def sig_to_db_phase(self, sig):\n",
    "        \"\"\" get dB and phase spectrograms of signal\n",
    "            example usage:\n",
    "                >>> sig, sr = torchaudio.load('sound.wav')\n",
    "                >>> db, phase = chvoice.sig_to_db_phase(sig)\n",
    "        \"\"\"\n",
    "        # represent input signal in time-frequency domain\n",
    "        stft = self.stft(sig)\n",
    "        # magnitude = amount of power/volume for each phase = frequency\n",
    "        mag, phase = ta.functional.magphase(stft)\n",
    "        # put magnitudes on log scale\n",
    "        db = self.amplitude_to_db(mag)\n",
    "\n",
    "        return db, phase\n",
    "\n",
    "    def db_phase_to_sig(self, db, phase):\n",
    "        \"\"\" get wav signal from db and phase spectrograms.\n",
    "            example usage:\n",
    "                >>> sig, sr = torchaudio.load('sound.wav')\n",
    "                >>> db, phase = chvoice.sig_to_db_phase(sig)\n",
    "                    ... do stuff to db ...\n",
    "                >>> recovered_sig = chvoice.spec_to_sig(db, phase)\n",
    "        \"\"\"\n",
    "        # go from log scale back to linear\n",
    "        mag = self.db_to_amplitude(db)\n",
    "        # recover full fourier transform of signal\n",
    "        real = mag * T.cos(phase)\n",
    "        imaginary = mag * T.sin(phase)\n",
    "        complex = T.stack((real, imaginary), dim=-1)\n",
    "        # inverse fourier transform to get signal\n",
    "        sig = complex.istft(\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_len\n",
    "        )\n",
    "\n",
    "        return sig\n",
    "\n",
    "\n",
    "### CREDIT : https://github.com/milesial/Pytorch-UNet\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(\n",
    "                scale_factor=2,\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "            self.conv = DoubleConv(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                in_channels // 2\n",
    "            )\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                in_channels // 2,\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            )\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = T.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = UNet(1, 1).to(DEVICE)\n",
    "model.load_state_dict(T.load('static/model_weights.pkl', map_location=DEVICE))\n",
    "model = model.to(DEVICE)\n",
    "dsp = DSP(254)\n",
    "\n",
    "noisy_sig, _ = librosa.load('vidx/p232_001.wav', sr=16000)\n",
    "noisy_sig = T.from_numpy(noisy_sig)\n",
    "db, phase = dsp.sig_to_db_phase(noisy_sig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 220])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = db.unsqueeze(0).unfold(2, 128, 128).squeeze(0).movedim(1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = T.mean(chunks)\n",
    "std = T.std(chunks)\n",
    "chunks = (chunks - 32) / 18\n",
    "chunks = chunks.unsqueeze(1).to(DEVICE)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = T.empty_like(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0/1\n"
     ]
    }
   ],
   "source": [
    "with T.no_grad():\n",
    "    for idx in range(0, len(chunks), 64):\n",
    "        print(f'batch {idx}/{len(chunks)}')\n",
    "        proc[idx:idx+64] = model(chunks[idx:idx+64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0595,  1.2238,  1.2269,  ...,  1.6178,  1.4083,  1.2772],\n",
       "          [ 1.0330,  1.3350,  1.3827,  ...,  1.8369,  1.6164,  1.5232],\n",
       "          [ 0.9786,  1.0791,  1.2370,  ...,  2.0669,  1.8612,  1.6736],\n",
       "          ...,\n",
       "          [ 0.4908, -0.6945, -0.3538,  ..., -0.1278, -0.0754, -0.0190],\n",
       "          [ 0.6045, -0.7678, -0.6551,  ..., -0.2654, -0.3965,  0.0403],\n",
       "          [ 0.5626, -0.5024, -0.8177,  ..., -0.5210, -0.4075,  0.0448]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proc = (proc * 18) + 32\n",
    "\n",
    "db_out = T.cat([c for c in proc.squeeze(1)], dim=1)\n",
    "phase_clipped = phase[:, :db_out.size(1)]\n",
    "sig = dsp.db_phase_to_sig(db_out, phase_clipped)\n",
    "sf.write('vidx/testpath.wav', sig, 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
